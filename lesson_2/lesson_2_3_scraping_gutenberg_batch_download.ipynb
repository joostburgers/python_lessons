{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eeec92f-86c4-4e8d-8ea0-6dd3b76f2ed6",
   "metadata": {},
   "source": [
    "# Lesson 2_3: Scraping Gutenberg: Batch Download\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ffb32-f421-4d3e-bc11-627168b57a6c",
   "metadata": {},
   "source": [
    "## 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a0fad-94cc-4c02-85d1-7a090e913245",
   "metadata": {},
   "source": [
    "Up to this point, we have only downloaded and modified a data table we found on Gutenberg. This table is important because it contains the `ID` numbers for every Gutenberg text. With these numbers we can scrape and access virtually every text because the naming conventions for each individual site are consistent.\n",
    "\n",
    "For example, the `txt` file for *Huckleberry Finn* by Mark Twain is stored here:\n",
    "\n",
    "https://www.gutenberg.org/cache/epub/76/pg76.txt\n",
    "\n",
    "Meanwhile the `txt` file for *Tom Sawyer* by Mark Twain is stored here:\n",
    "\n",
    "https://www.gutenberg.org/cache/epub/74/pg74.txt\n",
    "\n",
    "The only difference is that one is stored at `76` and the other is stored at `74`. Consequently, if we want to download a batch of specific files, we only really need their ID numbers, since this is the only thing that changes in the web address.\n",
    "\n",
    "Indeed, we could simply make a list of ID's we want to download and loop through it. We can write this out as pseudo-code as something like this.\n",
    "\n",
    "```python\n",
    "df_texts = []\n",
    "list1 = [74, 75, 76]\n",
    "for x in list1:\n",
    "    new_text = download_text('https://www.gutenberg.org/cache/epub/' +x)\n",
    "    df_texts.append(new_text)\n",
    "```\n",
    "The above code won't work but this is the core principle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6b73e-15bb-4d94-a7c7-66af97a740e4",
   "metadata": {},
   "source": [
    "## 2 Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb484ff-85a3-4f0e-b57c-dc259ae7175d",
   "metadata": {},
   "source": [
    "There are a number of technical issues with simply looping through a whole bunch of Gutenberg sites and downloading these texts. Explaining these technical issues in full is not very interesting and beyond the scope of this course. Briefly they include:\n",
    "- Gutenberg doesn't like robots, so we have to use specific servers\n",
    "- Not all texts are on the same servers so we have to switch servers\n",
    "- The web address is not always 100% the same\n",
    "- The text still has metadata\n",
    "\n",
    "Fortunately, a kind [coder](https://skeptric.com/gutenberg/) has already solved many of these problems. All I have done is modified some of their code for our purposes. We won't get bogged down with the details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bb80ff-ba8c-4842-9052-f81b5662f987",
   "metadata": {},
   "source": [
    "## 3 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d718170-f5f5-4b1c-a69a-ccf7bc4cd394",
   "metadata": {},
   "source": [
    "We will be using the `tqdm` package to check our progress when we download the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f2bf5-f380-4ded-a961-764648f0fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tqdm  # Replace with the package you want to check\n",
    "    print(\"tqdm is already installed.\")\n",
    "except ImportError:\n",
    "    print(\"tqdm is not installed. Installing...\")\n",
    "    # Use magic command to install the package\n",
    "    %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46168b-e2e1-42e6-83bc-b8a73b3eadc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import re            # Use regular rexpressions\n",
    "from io import BytesIO  # For handling byte streams (used for unzipping files)\n",
    "from tqdm import tqdm  # For showing a progress bar when downloading multiple files\n",
    "import requests  # This library helps us download web pages\n",
    "import logging   # This library helps us print helpful messages to understand what the code is doing\n",
    "import zipfile   # Helps unzip files that are compressed\n",
    "import chardet   # Detects the encoding of text\n",
    "import pandas as pd  # Pandas helps us work with tables of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2673a679-5a4b-4002-ab01-360e77a5138e",
   "metadata": {},
   "source": [
    "### 3.1 Get Web scraping server info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d4c55-c833-4546-92c1-54fa9a638f34",
   "metadata": {},
   "source": [
    "Get the page that has a list of all of the robot servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac44512-940f-4b47-ae77-9f71ac6fe6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gutenberg_robot_url = \"http://www.gutenberg.org/robot/harvest?filetypes[]=txt\"\n",
    "r = requests.get(gutenberg_robot_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a597f20-d8e1-4419-8a65-464093f0da61",
   "metadata": {},
   "source": [
    "Get the link for each individual mirror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78597e53-d635-4dae-bb3f-6e8b189229ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gutenberg_mirror = re.search('(https?://[^/]+)[^\"]*.zip', r.text).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e060ccc8-8775-49b2-9e33-0105015e40eb",
   "metadata": {},
   "source": [
    "### 3.2 Loop through mirrors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c469a-2128-42f1-8281-d3930f5de067",
   "metadata": {},
   "source": [
    "Search through each mirror to see if it has the file we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db53758-8f96-4896-b718-fe68809eca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gutenberg_text_urls(id: str, mirror=gutenberg_mirror, suffixes=(\"\", \"-8\", \"-0\")) -> list[str]:\n",
    "    \"\"\"\n",
    "    Generate URLs to download the Gutenberg book by ID.\n",
    "    \n",
    "    Args:\n",
    "        id (str): The book ID from Project Gutenberg.\n",
    "        mirror (str): The mirror URL for Project Gutenberg.\n",
    "        suffixes (tuple): Possible suffixes for the book file.\n",
    "        \n",
    "    Returns:\n",
    "        list[str]: A list of possible URLs for downloading the book.\n",
    "    \"\"\"\n",
    "    # Convert id to a string to ensure slicing works\n",
    "    id = str(id)  \n",
    "    \n",
    "    # The path is created using all but the last character of the ID, or '0' if the ID is short\n",
    "    path = \"/\".join(id[:-1]) or \"0\"\n",
    "    \n",
    "    # Generate URLs using the mirror, path, and suffixes for both .zip and .txt files\n",
    "    zip_urls = [f\"{mirror}/{path}/{id}/{id}{suffix}.zip\" for suffix in suffixes]\n",
    "    txt_urls = [f\"{mirror}/{path}/{id}/{id}{suffix}.txt\" for suffix in suffixes]\n",
    "    \n",
    "    return zip_urls + txt_urls  # Return both zip and text URLs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581975d3-2b83-4b4d-9335-32dd9851d05d",
   "metadata": {},
   "source": [
    "### 3.3 Create Download Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf54f7d-699f-4e3d-91ad-eb9dba9ee898",
   "metadata": {},
   "source": [
    "Create a download function to get and extract each individual book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323afad-b308-44d8-8c4b-935f12eef327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def download_gutenberg(id: str) -> str:\n",
    "    \"\"\"\n",
    "    Download the book from Project Gutenberg by its ID,\n",
    "    and unzip the content if necessary.\n",
    "    \n",
    "    Args:\n",
    "        id (str): Gutenberg book ID.\n",
    "    \n",
    "    Returns:\n",
    "        str: The content of the book as a text string or an error message.\n",
    "    \"\"\"\n",
    "    urls_to_try = gutenberg_text_urls(id) + [\n",
    "        f\"https://www.gutenberg.org/cache/epub/{id}/pg{id}.txt\"\n",
    "    ]\n",
    "\n",
    "    for url in urls_to_try:\n",
    "        try:\n",
    "            # Make the request and handle redirects\n",
    "         #   print(f'Downloading {id} at {url}')\n",
    "\n",
    "            r = requests.get(url, allow_redirects=True)\n",
    "            \n",
    "            # Check for any 404 errors\n",
    "            if r.status_code == 404:\n",
    "                logging.warning(f\"404 for {url} - moving to next possible URL.\")\n",
    "                continue\n",
    "            \n",
    "            # Raise an HTTPError if the status is 4XX or 5XX\n",
    "            r.raise_for_status()\n",
    "\n",
    "            # Log the final URL after any redirection\n",
    "            logging.info(f\"Final URL after redirection: {r.url}\")\n",
    "\n",
    "            # Check if the content is empty\n",
    "            if not r.text.strip():\n",
    "                logging.warning(f\"Empty content at {url} - moving to next possible URL.\")\n",
    "                continue\n",
    "            \n",
    "            # If content is valid, break and use it\n",
    "            logging.info(f\"Downloaded content from {r.url}\")\n",
    "            break\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.error(f\"Error fetching {url}: {e}\")\n",
    "            continue\n",
    "    else:\n",
    "        logging.error(f\"All attempts failed for Gutenberg ID {id}\")\n",
    "        return \"Unable to download file\"\n",
    "\n",
    "    # Handle .zip files or regular text files\n",
    "    if 'application/zip' in r.headers.get('Content-Type', ''):\n",
    "        z = zipfile.ZipFile(BytesIO(r.content))\n",
    "        if len(z.namelist()) != 1:\n",
    "            return \"Unable to download file\"  # Return error if unexpected file count\n",
    "        \n",
    "        # Read the file and detect encoding\n",
    "        file_content = z.read(z.namelist()[0])\n",
    "        encoding = chardet.detect(file_content)['encoding']\n",
    "        return file_content.decode(encoding)  # Decode using detected encoding\n",
    "    else:\n",
    "        return r.text  # Return text content if itâ€™s not a zip file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deedd068-7688-4ce5-80c4-b61d6fae1b4c",
   "metadata": {},
   "source": [
    "### 3.4 Strip Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36804861-18cf-426a-b7b0-d646e6847d6b",
   "metadata": {},
   "source": [
    "Use a small helper function to strip all of hte metadata from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be673f9-0129-4c40-b667-86862f8b62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "\n",
    "def strip_headers(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Strips the Project Gutenberg header and footer from the text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The full text of the book, potentially including headers and footers.\n",
    "    \n",
    "    Returns:\n",
    "        str: The text of the book without the Project Gutenberg header and footer.\n",
    "    \"\"\"\n",
    "    # Patterns to match the start and end of the main text in different versions\n",
    "    header_patterns = [\n",
    "        r\"\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK .* \\*\\*\\*\",  # Common header pattern\n",
    "        r\"Project Gutenberg's .*\",  # Alternative header for older books\n",
    "        r\"START OF THE PROJECT GUTENBERG EBOOK\",  # Some books may have this\n",
    "    ]\n",
    "    \n",
    "    footer_patterns = [\n",
    "        r\"\\*\\*\\* END OF THIS PROJECT GUTENBERG EBOOK .* \\*\\*\\*\",  # Common footer pattern\n",
    "        r\"End of Project Gutenberg's .*\",  # Alternative footer for older books\n",
    "        r\"END OF THE PROJECT GUTENBERG EBOOK\",  # Some books may have this\n",
    "    ]\n",
    "    \n",
    "    # Try matching headers\n",
    "    header_found = False\n",
    "    for pattern in header_patterns:\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            text = re.split(pattern, text, maxsplit=1, flags=re.IGNORECASE)[-1]\n",
    "            header_found = True\n",
    "            logging.info(\"Header stripped using pattern: \" + pattern)\n",
    "            break\n",
    "\n",
    "    # If no header was found, log a warning\n",
    "    if not header_found:\n",
    "        logging.warning(\"No recognizable header found.\")\n",
    "\n",
    "    # Try matching footers\n",
    "    footer_found = False\n",
    "    for pattern in footer_patterns:\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            text = re.split(pattern, text, maxsplit=1, flags=re.IGNORECASE)[0]\n",
    "            footer_found = True\n",
    "            logging.info(\"Footer stripped using pattern: \" + pattern)\n",
    "            break\n",
    "\n",
    "    # If no footer was found, log a warning\n",
    "    if not footer_found:\n",
    "        logging.warning(\"No recognizable footer found.\")\n",
    "\n",
    "    # Return the cleaned text, ensuring the entire text is not stripped\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8db42-8cbf-44a2-8db6-71e188051751",
   "metadata": {},
   "source": [
    "### 3.4 Download and Strip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb6908b-90af-42ec-95d0-f7a0163db9ec",
   "metadata": {},
   "source": [
    "Create a main function that runs the above two functions to download an individual book clean it and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f86c4-4668-4ddc-a6dc-171a0e992bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_text(book_id):\n",
    "    \"\"\"\n",
    "    Fetches and returns the text content of a book from Project Gutenberg using the book ID.\n",
    "    \n",
    "    Args:\n",
    "        book_id (str): The Gutenberg book ID.\n",
    "    \n",
    "    Returns:\n",
    "        str: The cleaned book text.\n",
    "    \"\"\"\n",
    "    # download_gutenberg already returns the text content as a string\n",
    "    text = download_gutenberg(book_id)\n",
    "    \n",
    "    # Clean the text by stripping the headers/footers (optional, depends on your implementation)\n",
    "    clean_text = strip_headers(text)\n",
    "    \n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8766dd5-3b1e-4f4f-b421-242e6a71da5a",
   "metadata": {},
   "source": [
    "### 3.5 Create DataFrame column `text_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cee63d-d062-414a-a5f2-52d84e259c53",
   "metadata": {},
   "source": [
    "This function calls `book_text()` for each `text_id` in the supplied dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d063e3-9333-41b1-b8f9-22ea8cc3f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_text_data(df):\n",
    "    \"\"\"\n",
    "    Fetches text data for each book in the DataFrame and inserts it into the 'text_data' column.\n",
    "    If 'text_data' already exists, prompts the user for confirmation before overwriting.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): A DataFrame that contains a column with book IDs (e.g., 'text#').\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with an additional or updated 'text_data' column.\n",
    "    \"\"\"\n",
    "    # Check if 'text_data' column exists\n",
    "    if 'text_data' in df.columns:\n",
    "        overwrite = input(\"'text_data' column already exists. Do you want to overwrite it? (y/n): \").strip().lower()\n",
    "        if overwrite != 'y':\n",
    "            print(\"Operation aborted. No changes were made.\")\n",
    "            return df  # Return the DataFrame unchanged\n",
    "\n",
    "    else:\n",
    "        # Initialize 'text_data' with string dtype if not present\n",
    "        df['text_data'] = pd.Series(dtype=pd.StringDtype())\n",
    "\n",
    "    # Iterate over rows with tqdm progress bar\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Fetching text data\"):\n",
    "        text_id = row['text_id']  # Assuming 'text_id' column has the book IDs\n",
    "        text = book_text(text_id)  # Fetch the text data using book_text() function\n",
    "        \n",
    "        # Assign the fetched text directly to the 'text_data' column\n",
    "        df.loc[index, 'text_data'] = text\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4095450f-1b1b-4ee7-b8d8-8b77afcd791f",
   "metadata": {},
   "source": [
    "## 4 All you really need to know!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d4e18b-77c2-4cb4-b698-f3fdd119d29e",
   "metadata": {},
   "source": [
    "Since most of the scraping has been setup in this file, you are safe to simply import your `.pickle` file and then run the function `fetch_text_data()` with the name of the dataframe inside the parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738c125-0453-4fa1-af37-fed6d19c9635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_virginia = pd.read_pickle('virginia_history.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5f682-4e0f-43ff-abca-355d39d41943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_virginia.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3f4fc-68b6-42b1-823d-f463d80be3e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fetch_text_data(df_virginia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98355b3e-40f9-4cbc-be7b-0bfcfe2b1be1",
   "metadata": {},
   "source": [
    "We can see in the result that a new column has been created and that the full-text of each text has been written into each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f8fe3-5ba8-48e2-9f05-d66e2b0f27f4",
   "metadata": {},
   "source": [
    "Since it is hard to read the cells in the dataframe, by checking an individual cell. Since our column titles are lower case and do not have special characters or spaces, we can use dot notation to access the column: `df_virginia.text_data`. We can then use get the row of our choosing by using `.iloc[row_index]`. Finally, we can slice the string down to 1000 characters by using list slicing `[:1000]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ed1fe-a406-4a71-b4e0-00aa4a1b74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_virginia.text_data.iloc[3][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c216108-b9d3-4803-8eba-bee33fae45c0",
   "metadata": {},
   "source": [
    "### 4.1 Overwrite protection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d59a384-20d3-47d6-82cd-cd6b7fbb52ac",
   "metadata": {},
   "source": [
    "The function has overwrite protection built in. If the `text_data` column already exists you can choose not to run the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c383ff-1346-4bd3-9461-a8783191ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_text_data(df_virginia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734ec5a-b9f5-4e52-a1a0-6f5957e36ced",
   "metadata": {},
   "source": [
    "### 4.2 Save result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6562fe5-132a-4464-a28b-d4f2acfda5f9",
   "metadata": {},
   "source": [
    "Save the result as a pickle file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094e4aa-b2aa-448f-873f-346d5947ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_virginia.to_pickle('df_virginia_text.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faea582-436d-4865-a723-315f9163a4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
